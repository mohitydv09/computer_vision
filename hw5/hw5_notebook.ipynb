{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "from scipy.linalg import null_space\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_F(pts1, pts2):\n",
    "    # TO DO\n",
    "    return F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triangulation(P1, P2, pts1, pts2):\n",
    "    # TO DO\n",
    "    return pts3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def disambiguate_pose(Rs, Cs, pts3Ds):\n",
    "    # TO DO\n",
    "    return R, C, pts3D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rectification(K, R, C):\n",
    "    # TO DO\n",
    "    return H1, H2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dense_match(img1, img2, descriptors1, descriptors2):\n",
    "    # TO DO\n",
    "    return disparity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROVIDED functions\n",
    "def compute_camera_pose(F, K):\n",
    "    E = K.T @ F @ K\n",
    "    R_1, R_2, t = cv2.decomposeEssentialMat(E)\n",
    "    # 4 cases\n",
    "    R1, t1 = R_1, t\n",
    "    R2, t2 = R_1, -t\n",
    "    R3, t3 = R_2, t\n",
    "    R4, t4 = R_2, -t\n",
    "\n",
    "    Rs = [R1, R2, R3, R4]\n",
    "    ts = [t1, t2, t3, t4]\n",
    "    Cs = []\n",
    "    for i in range(4):\n",
    "        Cs.append(-Rs[i].T @ ts[i])\n",
    "    return Rs, Cs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_img_pair(img1, img2):\n",
    "    img = np.hstack((img1, img2))\n",
    "    if img1.ndim == 3:\n",
    "        plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    else:\n",
    "        plt.imshow(img, cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_find_match(img1, img2, pts1, pts2):\n",
    "    assert pts1.shape == pts2.shape, 'x1 and x2 should have same shape!'\n",
    "    img_h = img1.shape[0]\n",
    "    scale_factor1 = img_h/img1.shape[0]\n",
    "    scale_factor2 = img_h/img2.shape[0]\n",
    "    img1_resized = cv2.resize(img1, None, fx=scale_factor1, fy=scale_factor1)\n",
    "    img2_resized = cv2.resize(img2, None, fx=scale_factor2, fy=scale_factor2)\n",
    "    pts1 = pts1 * scale_factor1\n",
    "    pts2 = pts2 * scale_factor2\n",
    "    pts2[:, 0] += img1_resized.shape[1]\n",
    "    img = np.hstack((img1_resized, img2_resized))\n",
    "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    for i in range(pts1.shape[0]):\n",
    "        plt.plot([pts1[i, 0], pts2[i, 0]], [pts1[i, 1], pts2[i, 1]], 'b.-', linewidth=0.5, markersize=5)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_epipolar_lines(F, pts1, pts2, img1, img2):\n",
    "    assert pts1.shape == pts2.shape, 'x1 and x2 should have same shape!'\n",
    "    ax1 = plt.subplot(121)\n",
    "    ax2 = plt.subplot(122)\n",
    "    ax1.imshow(cv2.cvtColor(img1, cv2.COLOR_BGR2RGB))\n",
    "    ax2.imshow(cv2.cvtColor(img2, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    for i in range(pts1.shape[0]):\n",
    "        x1, y1 = int(pts1[i][0] + 0.5), int(pts1[i][1] + 0.5)\n",
    "        ax1.scatter(x1, y1, s=5)\n",
    "        p1, p2 = find_epipolar_line_end_points(img2, F, (x1, y1))\n",
    "        ax2.plot([p1[0], p2[0]], [p1[1], p2[1]], linewidth=0.5)\n",
    "\n",
    "    for i in range(pts2.shape[0]):\n",
    "        x2, y2 = int(pts2[i][0] + 0.5), int(pts2[i][1] + 0.5)\n",
    "        ax2.scatter(x2, y2, s=5)\n",
    "        p1, p2 = find_epipolar_line_end_points(img1, F.T, (x2, y2))\n",
    "        ax1.plot([p1[0], p2[0]], [p1[1], p2[1]], linewidth=0.5)\n",
    "\n",
    "    ax1.axis('off')\n",
    "    ax2.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_epipolar_line_end_points(img, F, p):\n",
    "    img_width = img.shape[1]\n",
    "    el = (F @ np.array([[p[0], p[1], 1]]).T).flatten()\n",
    "    p1, p2 = (0, int(-el[2] / el[1])), (img.shape[1], int((-img_width * el[0] - el[2]) / el[1]))\n",
    "    _, p1, p2 = cv2.clipLine((0, 0, img.shape[1], img.shape[0]), p1, p2)\n",
    "    return p1, p2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_camera_poses(Rs, Cs):\n",
    "    assert(len(Rs) == len(Cs) == 4)\n",
    "    fig = plt.figure()\n",
    "    R1, C1 = np.eye(3), np.zeros((3, 1))\n",
    "    for i in range(4):\n",
    "        R2, C2 = Rs[i], Cs[i]\n",
    "        ax = fig.add_subplot(2, 2, i+1, projection='3d')\n",
    "        draw_camera(ax, R1, C1)\n",
    "        draw_camera(ax, R2, C2)\n",
    "        set_axes_equal(ax)\n",
    "        ax.set_xlabel('x axis')\n",
    "        ax.set_ylabel('y axis')\n",
    "        ax.set_zlabel('z axis')\n",
    "        ax.view_init(azim=-90, elev=0)\n",
    "        ax.title.set_text('Configuration {}'.format(i))\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_camera_poses_with_pts(Rs, Cs, pts3Ds):\n",
    "    assert(len(Rs) == len(Cs) == 4)\n",
    "    fig = plt.figure()\n",
    "    R1, C1 = np.eye(3), np.zeros((3, 1))\n",
    "    for i in range(4):\n",
    "        R2, C2, pts3D = Rs[i], Cs[i], pts3Ds[i]\n",
    "        ax = fig.add_subplot(2, 2, i+1, projection='3d')\n",
    "        draw_camera(ax, R1, C1, 5)\n",
    "        draw_camera(ax, R2, C2, 5)\n",
    "        ax.plot(pts3D[:, 0], pts3D[:, 1], pts3D[:, 2], 'b.')\n",
    "        set_axes_equal(ax)\n",
    "        ax.set_xlabel('x axis')\n",
    "        ax.set_ylabel('y axis')\n",
    "        ax.set_zlabel('z axis')\n",
    "        ax.view_init(azim=-90, elev=0)\n",
    "        ax.title.set_text('Configuration {}'.format(i))\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_camera(ax, R, C, scale=0.2):\n",
    "    axis_end_points = C + scale * R.T  # (3, 3)\n",
    "    vertices = C + scale * R.T @ np.array([[1, 1, 1], [-1, 1, 1], [-1, -1, 1], [1, -1, 1]]).T  # (3, 4)\n",
    "    vertices_ = np.hstack((vertices, vertices[:, :1]))  # (3, 5)\n",
    "    C = C.flatten()  # (3, 1) -> (3,)\n",
    "\n",
    "    # draw coordinate system of camera\n",
    "    ax.plot([C[0], axis_end_points[0, 0]], [C[1], axis_end_points[1, 0]], [C[2], axis_end_points[2, 0]], 'r-')\n",
    "    ax.plot([C[0], axis_end_points[0, 1]], [C[1], axis_end_points[1, 1]], [C[2], axis_end_points[2, 1]], 'g-')\n",
    "    ax.plot([C[0], axis_end_points[0, 2]], [C[1], axis_end_points[1, 2]], [C[2], axis_end_points[2, 2]], 'b-')\n",
    "\n",
    "    # draw square window and lines connecting it to camera center\n",
    "    ax.plot(vertices_[0, :], vertices_[1, :], vertices_[2, :], 'k-')\n",
    "    ax.plot([C[0], vertices[0, 0]], [C[1], vertices[1, 0]], [C[2], vertices[2, 0]], 'k-')\n",
    "    ax.plot([C[0], vertices[0, 1]], [C[1], vertices[1, 1]], [C[2], vertices[2, 1]], 'k-')\n",
    "    ax.plot([C[0], vertices[0, 2]], [C[1], vertices[1, 2]], [C[2], vertices[2, 2]], 'k-')\n",
    "    ax.plot([C[0], vertices[0, 3]], [C[1], vertices[1, 3]], [C[2], vertices[2, 3]], 'k-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_axes_equal(ax):\n",
    "    x_limits = ax.get_xlim3d()\n",
    "    y_limits = ax.get_ylim3d()\n",
    "    z_limits = ax.get_zlim3d()\n",
    "\n",
    "    x_range, x_middle = abs(x_limits[1] - x_limits[0]), np.mean(x_limits)\n",
    "    y_range, y_middle = abs(y_limits[1] - y_limits[0]), np.mean(y_limits)\n",
    "    z_range, z_middle = abs(z_limits[1] - z_limits[0]), np.mean(z_limits)\n",
    "\n",
    "    plot_radius = 0.5*max([x_range, y_range, z_range])\n",
    "\n",
    "    ax.set_xlim3d([x_middle - plot_radius, x_middle + plot_radius])\n",
    "    ax.set_ylim3d([y_middle - plot_radius, y_middle + plot_radius])\n",
    "    ax.set_zlim3d([z_middle - plot_radius, z_middle + plot_radius])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_disparity_map(disparity):\n",
    "    disparity[disparity > 150] = 150\n",
    "    plt.imshow(disparity, cmap='jet')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    # read in left and right images as RGB images\n",
    "    img_left = cv2.imread('./left.bmp', 1)\n",
    "    img_right = cv2.imread('./right.bmp', 1)\n",
    "    visualize_img_pair(img_left, img_right)\n",
    "\n",
    "    # Step 0: get correspondences between image pair\n",
    "    data = np.load('./correspondence.npz')\n",
    "    pts1, pts2 = data['pts1'], data['pts2']\n",
    "    visualize_find_match(img_left, img_right, pts1, pts2)\n",
    "\n",
    "    # Step 1: compute fundamental matrix and recover four sets of camera poses\n",
    "    F = compute_F(pts1, pts2)\n",
    "    visualize_epipolar_lines(F, pts1, pts2, img_left, img_right)\n",
    "\n",
    "    K = np.array([[350, 0, 960/2], [0, 350, 540/2], [0, 0, 1]])\n",
    "    Rs, Cs = compute_camera_pose(F, K)\n",
    "    visualize_camera_poses(Rs, Cs)\n",
    "\n",
    "    # Step 2: triangulation\n",
    "    pts3Ds = []\n",
    "    P1 = K @ np.hstack((np.eye(3), np.zeros((3, 1))))\n",
    "    for i in range(len(Rs)):\n",
    "        P2 = K @ np.hstack((Rs[i], -Rs[i] @ Cs[i]))\n",
    "        pts3D = triangulation(P1, P2, pts1, pts2)\n",
    "        pts3Ds.append(pts3D)\n",
    "    visualize_camera_poses_with_pts(Rs, Cs, pts3Ds)\n",
    "\n",
    "    # Step 3: disambiguate camera poses\n",
    "    R, C, pts3D = disambiguate_pose(Rs, Cs, pts3Ds)\n",
    "\n",
    "    # Step 4: rectification\n",
    "    H1, H2 = compute_rectification(K, R, C)\n",
    "    img_left_w = cv2.warpPerspective(img_left, H1, (img_left.shape[1], img_left.shape[0]))\n",
    "    img_right_w = cv2.warpPerspective(img_right, H2, (img_right.shape[1], img_right.shape[0]))\n",
    "    visualize_img_pair(img_left_w, img_right_w)\n",
    "\n",
    "    # Step 5: generate disparity map\n",
    "    img_left_w = cv2.resize(img_left_w, (int(img_left_w.shape[1] / 2), int(img_left_w.shape[0] / 2)))  # resize image for speed\n",
    "    img_right_w = cv2.resize(img_right_w, (int(img_right_w.shape[1] / 2), int(img_right_w.shape[0] / 2)))\n",
    "    img_left_w = cv2.cvtColor(img_left_w, cv2.COLOR_BGR2GRAY)  # convert to gray scale\n",
    "    img_right_w = cv2.cvtColor(img_right_w, cv2.COLOR_BGR2GRAY)\n",
    "    data = np.load('./resource/hw5/dsift_descriptor.npz')\n",
    "    desp1, desp2 = data['descriptors1'], data['descriptors2']\n",
    "    disparity = dense_match(img_left_w, img_right_w, desp1, desp2)\n",
    "    visualize_disparity_map(disparity)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
